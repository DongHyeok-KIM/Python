{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenserflow\n",
    "# Multi_Valriable_linear_regression_study\n",
    "# 다변량 선형 회귀\n",
    "\n",
    "### 필요한 모듈 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "#필요한 모듈 세팅\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#텐서플로우 버전 확인\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.random.set.seed()\n",
    "초기값을 지정해주는 역활\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6824906] [0.12352133]\n",
      "[-0.44971013] [-0.1195507]\n",
      "[0.10465169] [-0.5310569]\n",
      "[0.00871658] [0.9146888]\n",
      "[0.9322157] [-0.9830651]\n",
      "[0.75815153] [-0.8079777]\n",
      "[0.9403155] [0.9424355]\n",
      "[-0.13535476] [0.84231853]\n",
      "[0.38905382] [-0.31614637]\n",
      "[0.7312207] [-0.14882922]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    a = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "    b = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "    print(a.numpy(),b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n",
      "[-0.41604972] [0.11082816]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    tf.random.set_seed(0)\n",
    "    a = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "    b = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "    print(a.numpy(),b.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2변량 선형회귀 -1.변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set.seed()는 변수, 여기선 W1,W2값을 고정해 주는 역활.\n",
    "# 해당 코드를 몇번을 반복해도 같은 값을 돌려줌.\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "#변수 x1, x3 선언\n",
    "x1_data = [5.,0.,3.,4.,5.]\n",
    "x2_data = [4.,3.,1.,2.,0.]\n",
    "#정답인 y값 선언\n",
    "y_data  = [1.,2.,3.,4.,5.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2변량 선형회귀 -2.W초기값, learning_rate할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#변수가 2개이기 때문에 W(가중치, 기울기)도 2개를 선언\n",
    "#tf.random.uniform 균등분포를 따르는 난수를 생성, -10~10사이의수\n",
    "W1 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "W2 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "b = tf.Variable(tf.random.uniform((1,), -10, 10.0))\n",
    "\n",
    "learning_rate=tf.Variable(0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2변량 선형회귀 -3.경사하강법으로 cost, W1,W2,b도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 522.226257 |    -3.9860 |     1.1794 |  -6.053674\n",
      "   50 |  35.391602 |    -0.0499 |     2.3939 |  -5.107175\n",
      "  100 |  19.473316 |     0.7045 |     2.1722 |  -4.908693\n",
      "  150 |  15.734917 |     0.9508 |     1.8387 |  -4.810085\n",
      "  200 |  13.626745 |     1.0862 |     1.5601 |  -4.720336\n",
      "  250 |  12.331724 |     1.1771 |     1.3430 |  -4.628006\n",
      "  300 |  11.495358 |     1.2404 |     1.1748 |  -4.532677\n",
      "  350 |  10.919973 |     1.2838 |     1.0439 |  -4.435214\n",
      "  400 |  10.494151 |     1.3123 |     0.9411 |  -4.336432\n",
      "  450 |  10.155027 |     1.3298 |     0.8595 |  -4.236956\n",
      "  500 |   9.867114 |     1.3391 |     0.7937 |  -4.137262\n",
      "  550 |   9.610357 |     1.3423 |     0.7400 |  -4.037704\n",
      "  600 |   9.373407 |     1.3409 |     0.6954 |  -3.938541\n",
      "  650 |   9.149802 |     1.3361 |     0.6576 |  -3.839968\n",
      "  700 |   8.935852 |     1.3288 |     0.6250 |  -3.742122\n",
      "  750 |   8.729431 |     1.3197 |     0.5963 |  -3.645109\n",
      "  800 |   8.529282 |     1.3092 |     0.5707 |  -3.549000\n",
      "  850 |   8.334658 |     1.2978 |     0.5474 |  -3.453849\n",
      "  900 |   8.145084 |     1.2857 |     0.5259 |  -3.359690\n",
      "  950 |   7.960254 |     1.2732 |     0.5058 |  -3.266548\n",
      " 1000 |   7.779940 |     1.2603 |     0.4867 |  -3.174435\n"
     ]
    }
   ],
   "source": [
    "#단순 선형회귀에서 사용한 경사하강법과 동일\n",
    "for i in range(1000+1):\n",
    "    #tape에 모든 with연산기록 저장\n",
    "    with tf.GradientTape() as tape:\n",
    "        #hypothesis(추론,공식)을 전해줍니다.\n",
    "        hypothesis = W1 * x1_data + W2* x2_data+b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1,W2, b])\n",
    "    W1.assign_sub(learning_rate * W1_grad)\n",
    "    W2.assign_sub(learning_rate * W2_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 ==0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "          i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2변량 선형회귀(메트릭스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 858.094421 |    -3.9484 |    -5.7427 |   1.163832\n",
      "   50 |  29.465967 |     0.4849 |    -2.7273 |   2.405365\n",
      "  100 |   7.518828 |     0.9309 |    -1.9451 |   2.634386\n",
      "  150 |   4.350302 |     0.8506 |    -1.5717 |   2.709365\n",
      "  200 |   2.751280 |     0.7300 |    -1.3228 |   2.755810\n",
      "  250 |   1.850505 |     0.6302 |    -1.1412 |   2.793313\n",
      "  300 |   1.339502 |     0.5533 |    -1.0063 |   2.825848\n",
      "  350 |   1.048183 |     0.4946 |    -0.9060 |   2.854856\n",
      "  400 |   0.880757 |     0.4499 |    -0.8315 |   2.881201\n",
      "  450 |   0.783236 |     0.4156 |    -0.7763 |   2.905494\n",
      "  500 |   0.725190 |     0.3891 |    -0.7357 |   2.928197\n",
      "  550 |   0.689464 |     0.3686 |    -0.7060 |   2.949652\n",
      "  600 |   0.666392 |     0.3525 |    -0.6845 |   2.970117\n",
      "  650 |   0.650519 |     0.3398 |    -0.6691 |   2.989786\n",
      "  700 |   0.638773 |     0.3295 |    -0.6583 |   3.008808\n",
      "  750 |   0.629419 |     0.3212 |    -0.6509 |   3.027293\n",
      "  800 |   0.621478 |     0.3143 |    -0.6461 |   3.045323\n",
      "  850 |   0.614397 |     0.3085 |    -0.6432 |   3.062964\n",
      "  900 |   0.607862 |     0.3035 |    -0.6418 |   3.080263\n",
      "  950 |   0.601695 |     0.2991 |    -0.6414 |   3.097257\n",
      " 1000 |   0.595795 |     0.2953 |    -0.6418 |   3.113975\n"
     ]
    }
   ],
   "source": [
    "#이번엔 같은 예제를 메트릭스를 활용하여 도출.\n",
    "#메트릭스를 사용하지 않았을때(위예시)와 비교하면서 확인.\n",
    "#x와, y데이터를 따로따로 주었습니다.\n",
    "x_data = [\n",
    "    [5.,0.,3.,4.,5.],\n",
    "    [4.,3.,1.,2.,0.]\n",
    "]\n",
    "\n",
    "y_data = [1.,2.,3.,4.,5.]\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1,2), -10.0, 10.0))\n",
    "b = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\n",
    "\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) + b \n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "        W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "    if i % 50 ==0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3변량 단순 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |   15281.1172\n",
      "  500 |     625.5705\n",
      " 1000 |     538.3800\n"
     ]
    }
   ],
   "source": [
    "#값 고정 역활\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "\n",
    "# 데이터 세팅\n",
    "x1 = [ 60.,  91.,  78.,  64.,  74.]\n",
    "x2 = [ 70.,  87.,  60.,  80.,  67.]\n",
    "x3 = [ 73.,  92.,  93., 99.,  71.]\n",
    "Y  = [130., 170., 160., 170., 150.]\n",
    "\n",
    "# 변수만큼 w갯수 세팅\n",
    "w1 = tf.Variable(tf.random.normal((1,)))\n",
    "w2 = tf.Variable(tf.random.normal((1,)))\n",
    "w3 = tf.Variable(tf.random.normal((1,)))\n",
    "b  = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "\n",
    "learning_rate = 0.000001\n",
    "print(\"epoch | cost\")\n",
    "#경사하강법\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1* x1 + w2*x2 + w3*x3 + b\n",
    "        cost =tf.reduce_mean(tf.square(hypothesis -Y))\n",
    "        \n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1,w2,w3,b])\n",
    "    \n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3변량 단순 선형회귀(메트릭스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 | 2483.050293 |     1.6077 |     2.4433 |  -1.174632\n",
      "   50 | 812.191284 |     1.4626 |     2.2968 |  -1.176452\n",
      "  100 | 760.821167 |     1.4322 |     2.2640 |  -1.176727\n",
      "  150 | 749.294678 |     1.4199 |     2.2491 |  -1.176760\n",
      "  200 | 738.898804 |     1.4105 |     2.2370 |  -1.176755\n",
      "  250 | 728.683472 |     1.4015 |     2.2254 |  -1.176743\n",
      "  300 | 718.622498 |     1.3928 |     2.2140 |  -1.176731\n",
      "  350 | 708.713074 |     1.3841 |     2.2026 |  -1.176719\n",
      "  400 | 698.951843 |     1.3756 |     2.1914 |  -1.176707\n",
      "  450 | 689.338745 |     1.3671 |     2.1801 |  -1.176695\n",
      "  500 | 679.869019 |     1.3587 |     2.1690 |  -1.176683\n",
      "  550 | 670.542236 |     1.3504 |     2.1579 |  -1.176671\n",
      "  600 | 661.355774 |     1.3421 |     2.1468 |  -1.176659\n",
      "  650 | 652.306458 |     1.3340 |     2.1359 |  -1.176647\n",
      "  700 | 643.393311 |     1.3259 |     2.1250 |  -1.176635\n",
      "  750 | 634.614380 |     1.3179 |     2.1141 |  -1.176623\n",
      "  800 | 625.966370 |     1.3100 |     2.1034 |  -1.176612\n",
      "  850 | 617.448181 |     1.3022 |     2.0927 |  -1.176600\n",
      "  900 | 609.058105 |     1.2944 |     2.0820 |  -1.176588\n",
      "  950 | 600.792847 |     1.2867 |     2.0715 |  -1.176576\n",
      " 1000 | 592.652344 |     1.2791 |     2.0609 |  -1.176564\n"
     ]
    }
   ],
   "source": [
    "#np배열로 x와 y 선언\n",
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 60.,  70.,  73., 130. ],\n",
    "    [ 91.,  87.,  92., 170. ],\n",
    "    [ 78.,  60.,  93., 160. ],\n",
    "    [ 64.,  80., 99., 170. ],\n",
    "    [ 74.,  67.,  71., 150. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# 슬라이스로, 엑스와, y를 명확히 선언및 대입\n",
    "X = data[:, :-1]\n",
    "y = data[:, [-1]]\n",
    "\n",
    "#x의 변수가 3개인것을 주의\n",
    "W = tf.Variable(tf.random.normal((3, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# hypothesis, prediction function\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "n_epochs = 1000\n",
    "for i in range(n_epochs+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "    # updates parameters (W and b)\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 ==0:\n",
    "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[1][0], b.numpy()[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다변량 선형회귀 요약\n",
    "다변량 선형회귀는 변수를 직접 선언하는것과, 메트릭스를 통해 선언 하는 두가지 방법이 있다.\n",
    "\n",
    "전자는 변수가 많을 경우 하나하나 모두 세팅을 해줘야하는 반면,   \n",
    "후자는 변수가 많아도 메트릭스를 사용해 한번만 세팅이 가능하다.\n",
    "\n",
    "더 빠른 결과, 정확도가 높은 결과를 도출 할 수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다변량 선형회귀 확인 및 예측(바로 위 예제를 통한)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130.],\n",
       "       [170.],\n",
       "       [160.],\n",
       "       [170.],\n",
       "       [150.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y값 확인\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60., 70., 73.],\n",
       "       [91., 87., 92.],\n",
       "       [78., 60., 93.],\n",
       "       [64., 80., 99.],\n",
       "       [74., 67., 71.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X값 확인\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-1.1765639], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b값 확인\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[145.7387 ],\n",
       "       [201.1421 ],\n",
       "       [127.85293],\n",
       "       [145.07324],\n",
       "       [159.49405]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict공식을 통한 해 도출\n",
    "predict(X).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.8966974]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x1,x2,x3값 할당한 후 예측값\n",
    "predict([[ 1.,  1.,  4.]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.8966974],\n",
       "       [236.59372  ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2개의 해 동시 도출\n",
    "predict([[ 1.,  1.,  4.],[ 145.,  50.,  50.]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.8966974],\n",
       "       [236.59372  ],\n",
       "       [159.49405  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3개의 해 동시 도출\n",
    "#특히 마지막 배열은 최초 선언시 주었던 x값임\n",
    "predict([[ 1.,  1.,  4.],[ 145.,  50.,  50.],[ 74.,  67.,  71.]]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
