{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 모듈 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이타 세팅\n",
    "부스트코스 softmax강의를 참고하였으며, 해당강의에서 제공한 데이타 샘플을 사용하여 아래예제를 공부 및 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv', delimiter = ',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 3.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 6.]\n",
      " [0. 1. 1. ... 0. 0. 1.]]\n",
      "(101, 17)\n"
     ]
    }
   ],
   "source": [
    "#데이타 확인, 101행 17열로 되어있는 데이터임\n",
    "print(xy)\n",
    "print(xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]]\n",
      "(101, 16)\n"
     ]
    }
   ],
   "source": [
    "#x데이터 확인\n",
    "#x데이터는 원본 데이터에서 마지막 열을 제외한 배열의 집합이다.\n",
    "#즉 해당데이터는 한행에 16가지 feature로 이루어져있고\n",
    "#총 101개의 x데이터가 들어있는것이다.\n",
    "#마지막 17번째 feature는 각 x데이터의 최종 해라고 할 수있는 분류값이 나와있다.\n",
    "x_data = xy[:,:-1]\n",
    "print(x_data)\n",
    "print(x_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 3. 0. 0. 0. 0. 3. 3. 0. 0. 1. 3. 6. 6. 6. 1. 0. 3. 0. 1. 1. 0. 1.\n",
      " 5. 4. 4. 0. 0. 0. 5. 0. 0. 1. 3. 0. 0. 1. 3. 5. 5. 1. 5. 1. 0. 0. 6. 0.\n",
      " 0. 0. 0. 5. 4. 6. 0. 0. 1. 1. 1. 1. 3. 3. 2. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 6. 3. 0. 0. 2. 6. 1. 1. 2. 6. 3. 1. 0. 6. 3. 1. 5. 4. 2. 2. 3. 0. 0. 1.\n",
      " 0. 5. 0. 6. 1.]\n",
      "(101,)\n"
     ]
    }
   ],
   "source": [
    "#마지막 17번째 feature\n",
    "#0-6까지 7가지로 분류 되는 것을 확인할 수있다.\n",
    "y_data = xy[:, -1]\n",
    "print(y_data)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류값 선언 및 배열화\n",
    "softmax함수 계산을 위한 배열 값을 준비해줘야한다.\n",
    "y데이터를 기반으로 준비할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#분류 가짓수를 선언해 준다 0-6\n",
    "nb_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]], shape=(101, 7), dtype=float32)\n",
      "(101, 7)\n"
     ]
    }
   ],
   "source": [
    "Y_one_hot = tf.one_hot(y_data.astype(np.int32), nb_classes)\n",
    "print(Y_one_hot)\n",
    "print(Y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W,b 초기값 설정\n",
    "softmax 사용을 위해 W값을 배열 ((x값의 행 값,(y값의 열값))으로 설정한다.\n",
    "b값은 (y값의 열값)으로 맞춰준다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal((16, nb_classes)), name='weight')\n",
    "b = tf.Variable(tf.random.normal((nb_classes,)), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
       "array([-0.1312149,  1.0880232, -0.6171837,  1.2881914, -1.2204108,\n",
       "        1.3029379, -1.2964671], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#값 확인\n",
    "W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6581287>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#값 확인\n",
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables 값에 담아주기\n",
    "variables = [W,b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
       "array([-0.1312149,  1.0880232, -0.6171837,  1.2881914, -1.2204108,\n",
       "        1.3029379, -1.2964671], dtype=float32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#값 확인\n",
    "variables[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.6581287>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#값 확인\n",
    "variables[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 선형회귀 함수\n",
    "def logit_fn(X):\n",
    "    return tf.matmul(X,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax함수\n",
    "#tf.nn.softmax(tf.matmul(X,W) + b) 가능\n",
    "def hypothesis(X):\n",
    "    return tf.nn.softmax(logit_fn(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#에러율, 오차율을 구하는 함수\n",
    "def cost_fn(X, Y):\n",
    "    logits = logit_fn(X)\n",
    "    cost_i = tf.keras.losses.categorical_crossentropy(y_true=Y, y_pred=logits, \n",
    "                                                      from_logits=True)    \n",
    "    cost = tf.reduce_mean(cost_i)    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#경사하강법\n",
    "def grad_fn(X,Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = cost_fn(X,Y)\n",
    "        grads = tape.gradient(loss, variables)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정확도, 예측률구하는 함수\n",
    "def prediction(X,Y):\n",
    "    pred = tf.argmax(hypothesis(X),1)\n",
    "    correct_prediction = tf.equal(pred, tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X,Y, epochs=1000, verbose = 100):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "    for i in range(epochs):\n",
    "        grads = grad_fn(X,Y)\n",
    "        optimizer.apply_gradients(zip(grads, variables))\n",
    "        if (i ==0) | ((i+1)%verbose==0):\n",
    "            acc= prediction(X,Y).numpy()\n",
    "            loss = cost_fn(X,Y).numpy()\n",
    "            print('Steps: {} Loss: {}, Acc: {}'.format(i+1, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 1 Loss: 4.020371437072754, Acc: 0.0891089141368866\n",
      "Steps: 100 Loss: 0.5662930011749268, Acc: 0.8217821717262268\n",
      "Steps: 200 Loss: 0.3781706988811493, Acc: 0.9009901285171509\n",
      "Steps: 300 Loss: 0.2842300534248352, Acc: 0.9306930899620056\n",
      "Steps: 400 Loss: 0.22640354931354523, Acc: 0.9405940771102905\n",
      "Steps: 500 Loss: 0.18729399144649506, Acc: 0.9504950642585754\n",
      "Steps: 600 Loss: 0.15929216146469116, Acc: 0.9702970385551453\n",
      "Steps: 700 Loss: 0.13843293488025665, Acc: 0.9702970385551453\n",
      "Steps: 800 Loss: 0.12239468097686768, Acc: 1.0\n",
      "Steps: 900 Loss: 0.10972172021865845, Acc: 1.0\n",
      "Steps: 1000 Loss: 0.09946618229150772, Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "fit(x_data, Y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_test = np.array([[1,0,0,1,0,0,1,1,1,1,0,0,4,0,0,1],\n",
    "                   [1,0,0,1,0,0,0,1,1,1,0,0,4,1,0,1]],dtype=np.float32)\n",
    "Y_one_hot_test = np.array([[1,0,0,0,0,0,0],\n",
    "                           [1,0,0,0,0,0,0]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-142-f84cc8a41e25>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-142-f84cc8a41e25>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ,dtype=np.float32)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array([[1,0,0,1,0,0,1,1,1,1,0,0,4,0,0,1],dtype=np.float32)\n",
    "Y_one_hot_test = np.array([[1,0,0,0,0,0,0],\n",
    "                           []],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
       "array([ 1.2568738,  0.7963417, -1.0362203,  0.8214337, -1.3501922,\n",
       "        1.4137075, -1.4880672], dtype=float32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.5212332>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(x_test, Y_one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
       " array([ 1.2568738,  0.7963417, -1.0362203,  0.8214337, -1.3501922,\n",
       "         1.4137075, -1.4880672], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5212332>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0],b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(7,), dtype=float32, numpy=\n",
       " array([ 1.2568738,  0.7963417, -1.0362203,  0.8214337, -1.3501922,\n",
       "         1.4137075, -1.4880672], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.5212332>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0],b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0006901056>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_fn(x_test, Y_one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
